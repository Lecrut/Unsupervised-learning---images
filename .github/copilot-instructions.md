# Instrukcja projektu: Uczenie Nienadzorowane - Inpainting i Super-Resolution Dzie≈Ç Sztuki

## Cel projektu

Celem projektu jest zbudowanie kompletnego systemu przetwarzania obraz√≥w dzie≈Ç sztuki z wykorzystaniem metod uczenia nienadzorowanego i samonadzorowanego. System powinien umo≈ºliwiaƒá:

1. Budowƒô reprezentacji obraz√≥w (embedding√≥w) za pomocƒÖ autoenkodera.
2. Klasteryzacjƒô obraz√≥w w przestrzeni latentnej (grupowanie styl√≥w / autor√≥w).
3. Uzupe≈Çnianie uszkodzonych fragment√≥w obraz√≥w (inpainting) przy u≈ºyciu metod neuronowych.
4. Zwiƒôkszanie rozdzielczo≈õci obraz√≥w (super-resolution) z wykorzystaniem modeli neuronowych.

Projekt obejmuje trzy poziomy zaawansowania (zgodnie z kryteriami oceny):

* **3.0:** Autoenkoder + klasteryzacja + proste uszkodzenia (maski kwadratowe)
* **4.0:** Rozszerzenie o modu≈Ç super-resolution
* **5.0:** Rozszerzenie o uzupe≈Çnianie nieregularnych uszkodze≈Ñ (np. maski losowe, krawƒôdzie, plamy)

---

## Wymagane biblioteki (z `requirements.txt`)

* **Deep Learning:** PyTorch (>=1.12), torchvision
* **Machine Learning:** scikit-learn (KMeans, DBSCAN, GaussianMixture, SpectralClustering)
* **Redukcja wymiarowo≈õci:** umap-learn, TSNE
* **Obliczenia naukowe:** numpy, scikit-image, imageio
* **Wizualizacja:** matplotlib, seaborn
* **Dataset:** Hugging Face datasets (WikiArt_Full lub huggan/wikiart)
* **Eksperymenty:** comet_ml, python-dotenv
* **GUI:** Streamlit lub Dash

---

## Struktura projektu

```
projekt/
‚îú‚îÄ‚îÄ data/                          # Dane (WikiArt)
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ damages.py             # Generowanie uszkodze≈Ñ obraz√≥w
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sampling.py            # Podzia≈Ç danych
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ augmentations.py       # Augmentacja danych
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autoencoder.py         # Autoenkoder / VAE
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ inpainting_model.py    # Model do uzupe≈Çniania obraz√≥w
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ superres_model.py      # Model do super-resolution
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ training.py            # Pƒôtla treningowa
‚îÇ       ‚îú‚îÄ‚îÄ analysis.py            # Analiza wynik√≥w i klaster√≥w
‚îÇ       ‚îú‚îÄ‚îÄ visualization.py       # Wizualizacje UMAP, klastr√≥w, rekonstrukcji
‚îÇ       ‚îú‚îÄ‚îÄ local_logger.py        # Logowanie lokalne
‚îÇ       ‚îî‚îÄ‚îÄ comet_logger.py        # Integracja z Comet ML
‚îú‚îÄ‚îÄ app_gui/                       # GUI (Streamlit / Dash)
‚îú‚îÄ‚îÄ local_logs/                    # Logi eksperyment√≥w
‚îú‚îÄ‚îÄ main.ipynb                     # Notebook g≈Ç√≥wny
‚îî‚îÄ‚îÄ requirements.txt
```

---

## Etapy projektu

### 1. Przygotowanie danych

* Pobierz zb√≥r `Artificio/WikiArt_Full` lub `huggan/wikiart` z Hugging Face.
* Ustal podzia≈Ç na zbiory: **train**, **val**, **test**.
* Znormalizuj dane i przygotuj odpowiedni DataLoader.

---

### 2. Budowa reprezentacji (Autoencoder / VAE)

* Encoder powinien redukowaƒá wymiar obrazu (256x256x3) do przestrzeni latentnej (128-512D).
* Decoder rekonstruuje obraz z reprezentacji latentnej.
* Model mo≈ºe byƒá konwolucyjny lub wariacyjny (VAE) ‚Äî wyb√≥r pozostaje otwarty.
* Funkcja straty: kombinacja MSE, SSIM i/lub innych metryk podobie≈Ñstwa.
* Dodaj regularizacjƒô (Dropout, BatchNorm) i mechanizmy wczesnego zatrzymania.

---

### 3. Klasteryzacja i analiza przestrzeni latentnej

* Wykorzystaj redukcjƒô wymiarowo≈õci (UMAP / TSNE) dla wizualizacji.
* Zastosuj klasyczne metody klasteryzacji (np. KMeans, GaussianMixture, DBSCAN).
* Oce≈Ñ jako≈õƒá grupowania metrykami typu Silhouette Score.
* Wizualizuj wyniki, koloruj punkty wg klas stylu i uzyskanych klastr√≥w.

---

### 4. Modu≈Ç inpaintingu

* Implementuj model potrafiƒÖcy uzupe≈Çniaƒá brakujƒÖce fragmenty obrazu.
* Dla poziomu 3.0 wystarczajƒÖ maski prostokƒÖtne (do 1/16 powierzchni).
* Dla poziomu 5.0 dodaj generowanie **nieregularnych masek** (np. z szumem, losowymi krawƒôdziami lub plamami).
* Model mo≈ºe byƒá oparty o autoenkoder, U-Net, VAE lub inne architektury konwolucyjne.
* Do oceny u≈ºyj SSIM, PSNR i MSE.

---

### 5. Modu≈Ç super-resolution (dla oceny 4.0 i wy≈ºszej)

* Zaimplementuj sieƒá uczƒÖcƒÖ siƒô zwiƒôkszania rozdzielczo≈õci obraz√≥w (np. z 128x128 do 256x256).
* Mo≈ºesz wykorzystaƒá architekturƒô opartƒÖ na CNN, Residual Blocks lub innych popularnych technikach SR.
* Wykorzystaj pary (niska jako≈õƒá ‚Üí wysoka jako≈õƒá) z WikiArt lub zsyntezowane downsamplowane dane.

---

### 6. Eksperymentowanie i ≈õledzenie wynik√≥w

* U≈ºyj **Comet ML** do logowania metryk, hiperparametr√≥w i przyk≈Çadowych obraz√≥w.
* Dodatkowo zapisz wyniki lokalnie w `local_logs/` (JSON / CSV).
* Konfiguracja (np. optimizer, learning rate, wagi strat) powinna byƒá zdefiniowana w pliku konfiguracyjnym lub `.env`, nie wpisana na sztywno w kodzie.

---

### 7. Interfejs graficzny (GUI)

* Przygotuj prosty interfejs (Streamlit lub Dash) umo≈ºliwiajƒÖcy:

  * wczytanie obrazu testowego,
  * wyb√≥r rodzaju uszkodzenia lub operacji (inpainting / super-resolution),
  * uruchomienie modelu i prezentacjƒô wynik√≥w na ≈ºywo.

---

## Metryki i ewaluacja

| Aspekt           | Metryka          | Cel                       |
| ---------------- | ---------------- | ------------------------- |
| Rekonstrukcja    | SSIM             | > 0.85                    |
| Rekonstrukcja    | PSNR             | > 25 dB                   |
| Klasteryzacja    | Silhouette Score | > 0.4                     |
| Super-resolution | PSNR, SSIM       | wzrost jako≈õci vs wej≈õcie |

---

## Dodatkowe mo≈ºliwo≈õci (dla chƒôtnych)

* Wykorzystanie **VAE** lub **Attention U-Net**.
* Transfer learning z modeli ImageNetowych (np. ResNet encoder).
* Warunkowe inpainting (na podstawie klas lub styl√≥w).
* Interpolacja w przestrzeni latentnej.
* Multi-scale learning (uczenie rekonstrukcji na r√≥≈ºnych rozdzielczo≈õciach).

---

## Dostarczane elementy

1. **Kod ≈∫r√≥d≈Çowy** w strukturze `src/`.
2. **Notebook analityczny** `main.ipynb` prezentujƒÖcy:
   * proces uczenia,
   * analizƒô latent space,
   * klasteryzacjƒô,
   * przyk≈Çady rekonstrukcji i super-resolution.
3. **Aplikacja GUI** (Streamlit/Dash) do prezentacji dzia≈Çania modelu.
4. **Logi eksperyment√≥w** (Comet ML + lokalne JSON).
5. **Raport z wynikami i wnioskami** (README lub sekcja w notebooku).

---

## Kryteria ocen

| Ocena   | Wymagania                                                                 |
| ------- | ------------------------------------------------------------------------- |
| **3.0** | Autoenkoder + klasteryzacja + inpainting prostych masek                   |
| **4.0** | Jak wy≈ºej + modu≈Ç super-resolution                                        |
| **5.0** | Jak wy≈ºej + inpainting nieregularnych uszkodze≈Ñ + GUI + kompletna analiza |

---

## Wskaz√≥wki i dobre praktyki

* Stosuj **early stopping**, **gradient clipping** i **harmonogram uczenia** dla stabilno≈õci.
* Eksperymentuj z **latent_dim**, **g≈Çƒôboko≈õciƒÖ sieci** i **typami strat**.
* Wersjonuj eksperymenty (Comet ML, lokalne logi).
* Zadbaj o czytelne wizualizacje (krzywe strat, rekonstrukcje, UMAP, wyniki GUI).

Powodzenia w realizacji projektu! üöÄ
