# Unsupervised Learning - Images# Unsupervised Learning - Images# Unsupervised Learning - Images# Unsupervised Learning - Images



System przetwarzania obrazÃ³w dzieÅ‚ sztuki wykorzystujÄ…cy uczenie nienadzorowane i architekturÄ™ DeepCluster.



## Architektura DeepClusterSystem przetwarzania obrazÃ³w dzieÅ‚ sztuki wykorzystujÄ…cy uczenie nienadzorowane i architekturÄ™ DeepCluster.



Projekt implementuje architekturÄ™ DeepCluster skÅ‚adajÄ…cÄ… siÄ™ z trzech etapÃ³w:



### Etap I - Uczenie Enkodera (EMC)## Architektura DeepClusterSystem przetwarzania obrazÃ³w dzieÅ‚ sztuki wykorzystujÄ…cy uczenie nienadzorowane i architekturÄ™ DeepCluster.Projekt zawierajÄ…cy kompletnÄ… implementacjÄ™ systemu przetwarzania obrazÃ³w dzieÅ‚ sztuki z wykorzystaniem metod uczenia nienadzorowanego:

- IMG: przetwarzanie wejÅ›ciowego obrazu

- DMG: generowanie znieksztaÅ‚conych wersji obrazu

- EMC: ekstrakcja reprezentacji latentnej

- Funkcje straty: rekonstrukcja + spÃ³jnoÅ›Ä‡ cech (contrastive loss)### Etap I - Uczenie Enkodera- **Autoencoder** + klasteryzacja przestrzeni latentnej



### Etap II - Klasteryzacja (PCA + ClusA)- IMG: przetwarzanie wejÅ›ciowego obrazu

- PCAModule: redukcja wymiarowoÅ›ci przestrzeni latentnej

- ClusA: przypisywanie klastrÃ³w (KMeans, DBSCAN, GMM, Spectral)- DMG: generowanie znieksztaÅ‚conych wersji obrazu## Architektura- **Inpainting** - uzupeÅ‚nianie uszkodzonych fragmentÃ³w (proste i nieregularne)



### Etap III - Inpainting (IMP + DEC)- EMC: ekstrakcja reprezentacji latentnej

- IMP: uzupeÅ‚nianie uszkodzonych fragmentÃ³w w latent space

- DEC: dekodowanie do przestrzeni obrazu- **Super-Resolution** - zwiÄ™kszanie rozdzielczoÅ›ci obrazÃ³w



## Cele projektu### Etap II - Klasteryzacja



Projekt realizuje zaÅ‚oÅ¼enia dla ocen:- PCAModule: redukcja wymiarowoÅ›ciProjekt implementuje architekturÄ™ DeepCluster skÅ‚adajÄ…cÄ… siÄ™ z trzech etapÃ³w:- **GUI** - interfejs Streamlit do demonstracji

- **3.0:** Autoencoder + klasteryzacja + inpainting prostych masek

- **4.0:** Rozszerzenie o moduÅ‚ super-resolution- ClusA: przypisywanie klastrÃ³w (KMeans, DBSCAN, GMM, Spectral)

- **5.0:** Inpainting nieregularnych uszkodzeÅ„ + GUI + kompletna analiza



## Struktura projektu

### Etap III - Inpainting

```

Unsupervised-learning---images/- IMP: uzupeÅ‚nianie w latent space### Etap I - Uczenie Enkodera (EMC)## ğŸ¯ Cele projektu

â”œâ”€â”€ main.ipynb              # GÅ‚Ã³wny notebook z eksperymentami

â”œâ”€â”€ src/- DEC: dekodowanie do przestrzeni obrazu

â”‚   â”œâ”€â”€ models/

â”‚   â”‚   â”œâ”€â”€ autoencoder.py          # Konwolucyjny autoencoder- IMG: przetwarzanie wejÅ›ciowego obrazu

â”‚   â”‚   â”œâ”€â”€ deepcluster_modules.py  # IMG, DMG, EMC, PCA, ClusA, IMP, DEC

â”‚   â”‚   â”œâ”€â”€ wrappers.py             # EncoderModel, ClusteringModel, CometModel## Struktura projektu

â”‚   â”‚   â”œâ”€â”€ inpainting_model.py     # U-Net, PartialConv, SimpleInpainting

â”‚   â”‚   â””â”€â”€ superres_model.py       # SuperRes, LightweightSR, ESPCN- DMG: generowanie znieksztaÅ‚conych wersji obrazuProjekt realizuje zaÅ‚oÅ¼enia dla ocen:

â”‚   â”œâ”€â”€ data/

â”‚   â”‚   â”œâ”€â”€ damages.py              # Generowanie uszkodzeÅ„ (maski, szum, linie)```

â”‚   â”‚   â”œâ”€â”€ sampling.py             # PodziaÅ‚ i prÃ³bkowanie danych

â”‚   â”‚   â”œâ”€â”€ splitting.py            # Train/val/test split, cross-validationsrc/- EMC: ekstrakcja reprezentacji latentnej- **3.0:** âœ… Autoencoder + klasteryzacja + inpainting prostych masek

â”‚   â”‚   â””â”€â”€ augmentations.py        # Augmentacje danych

â”‚   â””â”€â”€ utils/â”œâ”€â”€ data/

â”‚       â”œâ”€â”€ training.py             # Funkcje trenowania z early stopping

â”‚       â”œâ”€â”€ analysis.py             # Klasteryzacja (KMeans, DBSCAN, GMM)â”‚   â”œâ”€â”€ damages.py- Funkcje straty: rekonstrukcja + spÃ³jnoÅ›Ä‡ cech (contrastive loss)- **4.0:** âœ… Rozszerzenie o moduÅ‚ super-resolution

â”‚       â”œâ”€â”€ visualization.py        # Wizualizacje (UMAP, rekonstrukcje)

â”‚       â”œâ”€â”€ metrics.py              # SSIM, PSNR, MSE, MAEâ”‚   â”œâ”€â”€ sampling.py

â”‚       â””â”€â”€ local_logger.py         # Logowanie lokalne

â”œâ”€â”€ app_gui/â”‚   â”œâ”€â”€ splitting.py- **5.0:** âœ… Inpainting nieregularnych uszkodzeÅ„ + GUI + kompletna analiza

â”‚   â””â”€â”€ app.py                      # GUI Streamlit

â”œâ”€â”€ local_logs/                     # Logi eksperymentÃ³wâ”‚   â””â”€â”€ augmentations.py

â”œâ”€â”€ data/                           # Dane (WikiArt)

â”œâ”€â”€ requirements.txt                # ZaleÅ¼noÅ›ciâ”œâ”€â”€ models/### Etap II - Klasteryzacja (PCA + ClusA)

â””â”€â”€ README.md                       # Ten plik

```â”‚   â”œâ”€â”€ autoencoder.py



## Instalacjaâ”‚   â”œâ”€â”€ deepcluster_modules.py    # IMG, DMG, EMC, PCA, ClusA, IMP, DEC- PCA: redukcja wymiarowoÅ›ci przestrzeni latentnej## ğŸ“ Struktura projektu



### 1. Klonowanie repozytoriumâ”‚   â”œâ”€â”€ wrappers.py               # EncoderModel, ClusteringModel, CometModel



```bashâ”‚   â”œâ”€â”€ inpainting_model.py- ClusA: przypisywanie klastrÃ³w (KMeans, DBSCAN, GMM, Spectral)

git clone <URL_REPOZYTORIUM>

cd Unsupervised-learning---imagesâ”‚   â””â”€â”€ superres_model.py

```

â””â”€â”€ utils/```

### 2. Utworzenie wirtualnego Å›rodowiska

    â”œâ”€â”€ training.py

#### Windows (PowerShell)

```powershell    â”œâ”€â”€ analysis.py### Etap III - Inpainting (IMP + DEC)Unsupervised-learning---images/

py -m venv venv

.\venv\Scripts\Activate.ps1    â”œâ”€â”€ visualization.py

python -m pip install --upgrade pip

pip install -r requirements.txt    â”œâ”€â”€ metrics.py- IMP: uzupeÅ‚nianie uszkodzonych fragmentÃ³w w latent spaceâ”œâ”€â”€ main.ipynb              # ğŸš€ GÅ‚Ã³wny notebook z eksperymentami

```

    â””â”€â”€ local_logger.py

#### Linux/Mac

```bash```- DEC: dekodowanie do przestrzeni obrazuâ”œâ”€â”€ src/                    # Kod ÅºrÃ³dÅ‚owy

python3 -m venv venv

source venv/bin/activate

pip install --upgrade pip

pip install -r requirements.txt## Instalacjaâ”‚   â”œâ”€â”€ models/            

```



### 3. Konfiguracja Comet ML (opcjonalnie)

```bash## Struktura projektuâ”‚   â”‚   â”œâ”€â”€ autoencoder.py          # Konwolucyjny autoencoder

1. Skopiuj plik `.env.template` jako `.env`:

```bashpip install -r requirements.txt

copy .env.template .env  # Windows

cp .env.template .env    # Linux/Mac```â”‚   â”‚   â”œâ”€â”€ inpainting_model.py     # U-Net, PartialConv, SimpleInpainting

```



2. Edytuj plik `.env` i uzupeÅ‚nij swoje dane:

```envWindows:```â”‚   â”‚   â””â”€â”€ superres_model.py       # SuperRes, LightweightSR, ESPCN

COMET_API_KEY=twoj_api_key_z_comet_ml

COMET_PROJECT_NAME=nazwa_projektu```powershell

COMET_WORKSPACE=twoj_workspace

```py -m venv venvprojekt/â”‚   â”œâ”€â”€ data/              



3. Ustaw `USE_COMET = True` w notebooku.\venv\Scripts\Activate.ps1



## Uruchomieniepip install -r requirements.txtâ”œâ”€â”€ data/â”‚   â”‚   â”œâ”€â”€ damages.py              # Generowanie uszkodzeÅ„ (maski, szum, linie)



### Notebook```

```bash

jupyter notebook main.ipynbâ”œâ”€â”€ src/â”‚   â”‚   â”œâ”€â”€ sampling.py             # PodziaÅ‚ i prÃ³bkowanie danych

```

## Uruchomienie

### GUI

```bashâ”‚   â”œâ”€â”€ data/â”‚   â”‚   â”œâ”€â”€ splitting.py            # Train/val/test split, cross-validation

streamlit run app_gui/app.py

``````bash



## Opcje logowaniajupyter notebook main.ipynbâ”‚   â”‚   â”œâ”€â”€ damages.py            # Generowanie uszkodzeÅ„â”‚   â”‚   â””â”€â”€ augmentations.py        # Augmentacje danych



### Bez zewnÄ™trznych serwisÃ³w (domyÅ›lnie)```

- Ustaw `USE_COMET = False` i `USE_LOCAL_LOGGER = True`

- Wszystkie wyniki zapisywane lokalnie w folderze `local_logs/`â”‚   â”‚   â”œâ”€â”€ sampling.py           # PrÃ³bkowanie danychâ”‚   â””â”€â”€ utils/             



### Z Comet ML (opcjonalnie)lub GUI:

- Ustaw `USE_COMET = True` i `USE_LOCAL_LOGGER = True`

- Wyniki logowane do Comet ML + lokalnie```bashâ”‚   â”‚   â”œâ”€â”€ splitting.py          # PodziaÅ‚ train/val/testâ”‚       â”œâ”€â”€ training.py             # Funkcje trenowania z early stopping



### Tylko konsolastreamlit run app_gui/app.py

- Ustaw `USE_COMET = False` i `USE_LOCAL_LOGGER = False`

- Wyniki tylko w konsoli```â”‚   â”‚   â””â”€â”€ augmentations.py      # Augmentacjeâ”‚       â”œâ”€â”€ analysis.py             # Klasteryzacja (KMeans, DBSCAN, GMM)



## UÅ¼ycie moduÅ‚Ã³w



### DeepCluster Pipeline## Konfiguracjaâ”‚   â”œâ”€â”€ models/â”‚       â”œâ”€â”€ visualization.py        # Wizualizacje (UMAP, rekonstrukcje)

```python

from src.models import DeepClusterPipeline



model = DeepClusterPipeline(UtwÃ³rz plik `.env`:â”‚   â”‚   â”œâ”€â”€ autoencoder.py        # ConvAutoencoderâ”‚       â”œâ”€â”€ metrics.py              # SSIM, PSNR, MSE, MAE

    latent_dim=128,

    n_clusters=10,```env

    damage_type='mixed'

)COMET_API_KEY=twoj_kluczâ”‚   â”‚   â”œâ”€â”€ deepcluster_modules.py # IMG, DMG, EMC, PCA, ClusA, IMP, DECâ”‚       â””â”€â”€ local_logger.py         # Logowanie lokalne



outputs = model(images, return_all=True)COMET_PROJECT_NAME=nazwa_projektu

```

COMET_WORKSPACE=workspaceâ”‚   â”‚   â”œâ”€â”€ inpainting_model.py   # U-Net, PartialConvâ”œâ”€â”€ app_gui/               

### Klasy opakowujÄ…ce

```python```

from src.models import EncoderModel, ClusteringModel, InpaintingModel, CometModel

â”‚   â”‚   â””â”€â”€ superres_model.py     # Super-resolutionâ”‚   â””â”€â”€ app.py                      # ğŸ¨ GUI Streamlit

# Encoder

encoder = EncoderModel(latent_dim=128, device='cuda')## UÅ¼ycie

latent_vectors = encoder.extract_from_dataloader(train_loader, max_samples=5000)

â”‚   â””â”€â”€ utils/â”œâ”€â”€ local_logs/                     # Logi eksperymentÃ³w

# Klasteryzacja

clustering = ClusteringModel(n_clusters=10, algorithm='kmeans', use_pca=True)### DeepCluster Pipeline

labels = clustering.fit_predict(latent_vectors)

```pythonâ”‚       â”œâ”€â”€ training.py           # Funkcje trenowaniaâ”œâ”€â”€ data/                           # Dane (WikiArt)

# Inpainting

inpainter = InpaintingModel(latent_dim=128, n_clusters=10, device='cuda')from src.models import DeepClusterPipeline

reconstructed, damaged = inpainter.inpaint(images, labels)

â”‚       â”œâ”€â”€ analysis.py           # Klasteryzacja i analizaâ”œâ”€â”€ requirements.txt                # ZaleÅ¼noÅ›ci

# Logger

logger = CometModel("experiment_name", use_comet=True, use_local=True)model = DeepClusterPipeline(latent_dim=128, n_clusters=10, damage_type='mixed')

logger.log_parameters({'latent_dim': 128})

logger.log_metrics({'psnr': 28.5}, step=1)outputs = model(images, return_all=True)â”‚       â”œâ”€â”€ visualization.py      # Wizualizacjeâ””â”€â”€ README.md                       # Ten plik

logger.end()

``````



### ModuÅ‚y podstawoweâ”‚       â”œâ”€â”€ metrics.py            # PSNR, SSIM, MSE```

```python

from src.models import EMC, DMG, IMP, DEC, PCAModule, ClusA### Klasy opakowujÄ…ce



encoder = EMC(latent_dim=128)```pythonâ”‚       â””â”€â”€ local_logger.py       # Logowanie lokalne

dmg = DMG(damage_type='simple')

impainter = IMP(latent_dim=128, n_clusters=10)from src.models import EncoderModel, ClusteringModel, InpaintingModel, CometModel

decoder = DEC(latent_dim=128)

pca = PCAModule(n_components=50)â”œâ”€â”€ app_gui/## Instalacja

clusterer = ClusA(n_clusters=10, algorithm='kmeans')

```encoder = EncoderModel(latent_dim=128, device='cuda')



## Konfiguracja eksperymentulatent_vectors = encoder.extract_from_dataloader(train_loader, max_samples=5000)â”‚   â””â”€â”€ app.py                    # GUI Streamlit



### Split danych

```python

USE_QUICK_SPLIT = True   # 5000 prÃ³bek, ~1h treninguclustering = ClusteringModel(n_clusters=10, algorithm='kmeans', use_pca=True)â”œâ”€â”€ local_logs/                   # Logi eksperymentÃ³w### 1. Klonowanie repozytorium

USE_QUICK_SPLIT = False  # peÅ‚ny dataset, 3-6h

```labels = clustering.fit_predict(latent_vectors)



### Typy uszkodzeÅ„â”œâ”€â”€ main.ipynb                    # GÅ‚Ã³wny notebook```bash

```python

DAMAGE_TYPE = 'simple'     # Kwadratowe maskiinpainter = InpaintingModel(latent_dim=128, n_clusters=10, device='cuda')

DAMAGE_TYPE = 'irregular'  # Linie, plamy, szum

DAMAGE_TYPE = 'mixed'      # Wszystkie typyreconstructed, damaged = inpainter.inpaint(images, labels)â””â”€â”€ requirements.txtgit clone <URL_REPOZYTORIUM>

```



## FunkcjonalnoÅ›ci

logger = CometModel("experiment_name", use_comet=True, use_local=True)```cd Unsupervised-learning---images

### Podstawowe (ocena 3.0)

- Autoencoder z reprezentacjÄ… latentnÄ…logger.log_parameters({'latent_dim': 128})

- Klasteryzacja KMeans

- Inpainting prostych maseklogger.log_metrics({'psnr': 28.5}, step=1)```



### Rozszerzone (ocena 4.0)logger.end()

- Super-resolution

- Metryki PSNR, SSIM, MS-SSIM```## Wymagane biblioteki

- PorÃ³wnanie modeli



### Zaawansowane (ocena 5.0)

- Inpainting nieregularnych uszkodzeÅ„### ModuÅ‚y podstawowe### 2. Utworzenie wirtualnego Å›rodowiska (ZALECANE)

- GUI Streamlit

- Analiza klastrÃ³w```python

- PorÃ³wnanie algorytmÃ³w (KMeans, DBSCAN, GMM, Spectral)

- Wizualizacje UMAP/t-SNEfrom src.models import EMC, DMG, IMP, DEC, PCAModule, ClusA- PyTorch >= 1.12



## Metryki



- PSNR > 25 dB: bardzo dobra jakoÅ›Ä‡encoder = EMC(latent_dim=128)- torchvision#### Opcja A: UÅ¼ywajÄ…c venv (Windows)

- SSIM > 0.85: wysokie podobieÅ„stwo strukturalne

- Silhouette Score > 0.4: dobra jakoÅ›Ä‡ klasteryzacjidmg = DMG(damage_type='simple')



## Datasetimpainter = IMP(latent_dim=128, n_clusters=10)- scikit-learn```powershell



WikiArt z Hugging Face:decoder = DEC(latent_dim=128)

- Artificio/WikiArt_Full

- huggan/wikiart```- umap-learn# Tworzenie wirtualnego Å›rodowiska



## Wymagania systemowe



- Python 3.8+## FunkcjonalnoÅ›ci- scikit-imagepy -m venv venv

- CUDA (opcjonalnie, dla GPU)



## GÅ‚Ã³wne zaleÅ¼noÅ›ci

**Ocena 3.0:**- imageio

- PyTorch >= 1.12

- torchvision- Autoencoder z reprezentacjÄ… latentnÄ…

- scikit-learn

- umap-learn- Klasteryzacja KMeans- numpy# Aktywacja Å›rodowiska

- scikit-image

- matplotlib, seaborn- Inpainting prostych masek

- datasets (Hugging Face)

- comet_ml (opcjonalnie)- matplotlib.\venv\Scripts\Activate.ps1

- streamlit

**Ocena 4.0:**

## Licencja

- Super-resolution- seaborn

Projekt edukacyjny dla celÃ³w akademickich.

- Metryki PSNR, SSIM, MS-SSIM

- datasets (Hugging Face)# Instalacja zaleÅ¼noÅ›ci

**Ocena 5.0:**

- Inpainting nieregularnych uszkodzeÅ„- comet_ml (opcjonalnie)python -m pip install --upgrade pip

- GUI Streamlit

- Analiza klastrÃ³w- python-dotenvpip install -r requirements.txt

- PorÃ³wnanie algorytmÃ³w klasteryzacji

- Streamlit```

## Metryki



- PSNR > 25 dB: bardzo dobra jakoÅ›Ä‡

- SSIM > 0.85: wysokie podobieÅ„stwo strukturalne## Instalacja#### Opcja B: UÅ¼ywajÄ…c conda

- Silhouette Score > 0.4: dobra jakoÅ›Ä‡ klasteryzacji

```bash

## Dataset

```bashconda create -n unsupervised-learning python=3.9

WikiArt z Hugging Face (Artificio/WikiArt_Full lub huggan/wikiart)

pip install -r requirements.txtconda activate unsupervised-learning

```pip install -r requirements.txt

```

### Windows

```powershell#### Opcja C: Instalacja globalna (niezalecane)

py -m venv venv```bash

.\venv\Scripts\Activate.ps1pip install -r requirements.txt

pip install -r requirements.txt```

```

### 3. Uruchomienie

### Linux/Mac```bash

```bash# Upewnij siÄ™, Å¼e wirtualne Å›rodowisko jest aktywne (powinieneÅ› widzieÄ‡ (venv) w promcie)

python3 -m venv venvjupyter notebook main.ipynb

source venv/bin/activate```

pip install -r requirements.txtlub

``````bash

jupyter lab main.ipynb

## Uruchomienie```



### Notebook## ğŸ”§ Opcje logowania

```bash

jupyter notebook main.ipynb### âš¡ Szybkie testowanie

```Dla szybkich testÃ³w zmieÅ„ w notebooku:

```python

### GUIDATASET_SIZE = 'test'  # 100 obrazÃ³w, ~2 minuty trenowania

```bash```

streamlit run app_gui/app.py

```Inne opcje:

```python

lubDATASET_SIZE = 500     # ~5 minut trenowania

DATASET_SIZE = 1000    # ~10 minut trenowania  

```powershellDATASET_SIZE = 0.1     # 10% datasetu

.\start_gui.ps1DATASET_SIZE = 'full'  # PeÅ‚ny dataset (dÅ‚ugo!)

``````



## Konfiguracja### ğŸ“ Bez zewnÄ™trznych serwisÃ³w (domyÅ›lnie)

- Ustaw `USE_COMET = False` i `USE_LOCAL_LOGGER = True`

### Logowanie- Wszystkie wyniki zapisywane lokalnie w folderze `local_logs/`

- Wykresy i metryki automatycznie zapisywane jako pliki

UtwÃ³rz plik `.env` na podstawie `.env.template`:

### ğŸ“Š Z Comet ML (opcjonalnie)

```env1. Skopiuj plik `.env.template` jako `.env`:

COMET_API_KEY=twoj_klucz   ```bash

COMET_PROJECT_NAME=nazwa_projektu   copy .env.template .env

COMET_WORKSPACE=workspace   ```

```2. Edytuj plik `.env` i uzupeÅ‚nij swoje dane:

   ```env

W notebooku ustaw:   COMET_API_KEY=twoj_api_key_z_comet_ml

```python   COMET_PROJECT_NAME=nazwa_projektu

USE_COMET = True          # Comet ML   COMET_WORKSPACE=twoj_workspace

USE_LOCAL_LOGGER = True   # Lokalny logger   ```

```3. Ustaw `USE_COMET = True` w notebooku

4. Rejestracja na [comet.ml](https://www.comet.ml) wymagana

### Split danych

**WaÅ¼ne:** Plik `.env` jest automatycznie ignorowany przez git, wiÄ™c twoje dane pozostajÄ… bezpieczne.

```python

USE_QUICK_SPLIT = True   # 5000 prÃ³bek, ~1h treningu### ğŸ“ Tylko konsola

USE_QUICK_SPLIT = False  # peÅ‚ny dataset, 3-6h- Ustaw `USE_COMET = False` i `USE_LOCAL_LOGGER = False`

```- Wyniki tylko w konsoli, bez zapisywania



### Typy uszkodzeÅ„### 4. Deaktywacja Å›rodowiska (po zakoÅ„czeniu pracy)

```powershell

```pythondeactivate

DAMAGE_TYPE = 'simple'     # Kwadratowe maski```

DAMAGE_TYPE = 'irregular'  # Linie, plamy, szum

DAMAGE_TYPE = 'mixed'      # Wszystkie typy## ğŸ¯ Szybkie uruchomienie (Windows)

```

### Opcja 1: UÅ¼yj gotowego skryptu

## FunkcjonalnoÅ›ci```cmd

# Kliknij dwukrotnie na activate.bat

### Podstawowe (ocena 3.0)# lub w terminalu:

- Autoencoder z reprezentacjÄ… latentnÄ….\activate.bat

- Klasteryzacja KMeans```

- Inpainting prostych masek

### Opcja 2: PowerShell

### Rozszerzone (ocena 4.0)```powershell

- Super-resolution.\activate.ps1

- Metryki PSNR, SSIM, MS-SSIM```

- PorÃ³wnanie modeli

### Opcja 3: RÄ™cznie

### Zaawansowane (ocena 5.0)```powershell

- Inpainting nieregularnych uszkodzeÅ„.\venv\Scripts\Activate.ps1

- GUI Streamlitjupyter notebook main.ipynb

- Analiza klastrÃ³w```

- PorÃ³wnanie algorytmÃ³w (KMeans, DBSCAN, GMM, Spectral)

- Wizualizacje UMAP/t-SNE## âš ï¸ WaÅ¼ne uwagi

- **Zawsze aktywuj wirtualne Å›rodowisko** przed pracÄ… z projektem

## UÅ¼ycie moduÅ‚Ã³w- JeÅ›li widzisz `(venv)` na poczÄ…tku linii w terminalu - Å›rodowisko jest aktywne

- Na Windows uÅ¼ywaj `py` zamiast `python` do uruchamiania Pythona

### DeepCluster Pipeline- JeÅ›li masz problemy z PowerShell, sprÃ³buj uruchomiÄ‡ jako administrator

```python

from src.models import DeepClusterPipeline## Struktura projektu

```

model = DeepClusterPipeline(Unsupervised-learning---images/

    latent_dim=128,â”œâ”€â”€ main.ipynb              # gÅ‚Ã³wny notebook z eksperymentem

    n_clusters=10,â”œâ”€â”€ src/                    # kod ÅºrÃ³dÅ‚owy

    damage_type='mixed'â”‚   â”œâ”€â”€ __init__.py        # inicjalizacja pakietu

)â”‚   â”œâ”€â”€ models/            # modele PyTorch

â”‚   â”‚   â”œâ”€â”€ __init__.py   

# Forward passâ”‚   â”‚   â””â”€â”€ autoencoder.py # ConvAutoencoder

outputs = model(images, return_all=True)â”‚   â”œâ”€â”€ data/              # przetwarzanie danych

```â”‚   â”‚   â”œâ”€â”€ __init__.py   

â”‚   â”‚   â””â”€â”€ damages.py     # funkcje niszczenia obrazÃ³w

### PoszczegÃ³lne moduÅ‚yâ”‚   â””â”€â”€ utils/             # funkcje pomocnicze

```pythonâ”‚       â”œâ”€â”€ __init__.py   

from src.models import EMC, DMG, IMP, DEC, PCAModule, ClusAâ”‚       â”œâ”€â”€ training.py    # funkcje trenowania

â”‚       â”œâ”€â”€ analysis.py    # analiza latentna + klasteryzacja

encoder = EMC(latent_dim=128)â”‚       â””â”€â”€ visualization.py # wizualizacje

dmg = DMG(damage_type='simple')â”œâ”€â”€ requirements.txt        # lista zaleÅ¼noÅ›ci

impainter = IMP(latent_dim=128, n_clusters=10)â”œâ”€â”€ README.md              # ten plik

decoder = DEC(latent_dim=128)â”œâ”€â”€ setup.py               # plik instalacyjny pakietu

pca = PCAModule(n_components=50)â”œâ”€â”€ .gitignore             # pliki ignorowane przez git

clusterer = ClusA(n_clusters=10, algorithm='kmeans')â”œâ”€â”€ activate.bat           # skrypt aktywacji dla CMD (Windows)

```â”œâ”€â”€ activate.ps1           # skrypt aktywacji dla PowerShell (Windows)

â”œâ”€â”€ venv/                  # wirtualne Å›rodowisko (nie commitowane)

## Metrykiâ”œâ”€â”€ data/                  # folder na dane (nie commitowane)

â””â”€â”€ *.pth                  # zapisane modele (nie commitowane)

- PSNR > 25 dB: bardzo dobra jakoÅ›Ä‡```

- SSIM > 0.85: bardzo dobra podobieÅ„stwo strukturalne

- Silhouette Score > 0.4: dobra jakoÅ›Ä‡ klasteryzacji## ğŸ“š Opis moduÅ‚Ã³w



## Dane### ğŸ§  `src/models/autoencoder.py`

- `ConvAutoencoder` - konwolucyjny autoencoder z:

Projekt uÅ¼ywa datasetu WikiArt z Hugging Face:  - Encoder: 3 warstwy konwolucyjne + BatchNorm

- Artificio/WikiArt_Full  - Decoder: 3 warstwy transponowane konwolucyjne

- huggan/wikiart  - Metody: `encode()`, `decode()`, `reconstruct()`



## Licencja### ï¿½ `src/data/sampling.py`

- `LimitedDataset` - ogranicza liczbÄ™ prÃ³bek  

Projekt edukacyjny dla celÃ³w akademickich.- `QuickTestDataset` - maÅ‚y dataset do testÃ³w (50-100 prÃ³bek)

- `StratifiedLimitedDataset` - zachowuje proporcje klas
- `sample_dataset()` - rÃ³Å¼ne metody prÃ³bkowania
- ObsÅ‚uga: peÅ‚ny dataset, konkretna liczba, procent

### ï¿½ğŸ’¥ `src/data/damages.py`
- `random_mask()` - losowe biaÅ‚e plamy
- `rectangular_mask()` - prostokÄ…tne maski
- `noise_mask()` - szum w pikselach
- `line_damage()` - losowe linie
- `circular_mask()` - okrÄ…gÅ‚e maski
- `MaskedDataset` - dataset z losowymi uszkodzeniami
- `MultiDamageDataset` - kombinacja wielu uszkodzeÅ„

### ğŸƒâ€â™‚ï¸ `src/utils/training.py`
- `train_autoencoder()` - podstawowe trenowanie
- `validate_autoencoder()` - walidacja modelu
- `train_with_validation()` - trenowanie z early stopping

### ğŸ” `src/utils/analysis.py`
- `extract_latent_vectors()` - ekstrakcja reprezentacji
- `cluster_latent_space()` - KMeans/Spectral/DBSCAN
- `reduce_dimensionality()` - UMAP/t-SNE/PCA
- `cluster_and_visualize()` - kompletna analiza

### ğŸ“Š `src/utils/visualization.py`
- `visualize_reconstructions()` - porÃ³wnanie przed/po
- `plot_training_history()` - wykresy strat
- `visualize_latent_space_2d()` - embedding 2D
- `plot_cluster_analysis()` - szczegÃ³Å‚owa analiza klastrÃ³w
- `compare_damage_types()` - porÃ³wnanie typÃ³w uszkodzeÅ„
```
Unsupervised-learning---images/
â”œâ”€â”€ main.ipynb              # gÅ‚Ã³wny notebook z eksperymentem
â”œâ”€â”€ src/                    # kod ÅºrÃ³dÅ‚owy
â”‚   â”œâ”€â”€ __init__.py        # inicjalizacja pakietu
â”‚   â”œâ”€â”€ models/            # modele PyTorch
â”‚   â”‚   â”œâ”€â”€ __init__.py   
â”‚   â”‚   â””â”€â”€ autoencoder.py # ConvAutoencoder
â”‚   â”œâ”€â”€ data/              # przetwarzanie danych
â”‚   â”‚   â”œâ”€â”€ __init__.py   
â”‚   â”‚   â””â”€â”€ damages.py     # funkcje niszczenia obrazÃ³w
â”‚   â””â”€â”€ utils/             # funkcje pomocnicze
â”‚       â”œâ”€â”€ __init__.py   
â”‚       â”œâ”€â”€ training.py    # funkcje trenowania
â”‚       â”œâ”€â”€ analysis.py    # analiza latentna + klasteryzacja
â”‚       â””â”€â”€ visualization.py # wizualizacje
â”œâ”€â”€ requirements.txt        # lista zaleÅ¼noÅ›ci
â”œâ”€â”€ README.md              # ten plik
â”œâ”€â”€ setup.py               # plik instalacyjny pakietu
â”œâ”€â”€ .gitignore             # pliki ignorowane przez git
â”œâ”€â”€ activate.bat           # skrypt aktywacji dla CMD (Windows)
â”œâ”€â”€ activate.ps1           # skrypt aktywacji dla PowerShell (Windows)
â”œâ”€â”€ venv/                  # wirtualne Å›rodowisko (nie commitowane)
â”œâ”€â”€ data/                  # folder na dane (nie commitowany)
â””â”€â”€ *.pth                  # zapisane modele (nie commitowane)
```

## Wymagania systemowe
- Python 3.8+
- CUDA (opcjonalnie, dla GPU)

## GÅ‚Ã³wne zaleÅ¼noÅ›ci
- **PyTorch** - framework do deep learning
- **torchvision** - narzÄ™dzia do przetwarzania obrazÃ³w
- **pytorch-msssim** - obliczanie SSIM (Structural Similarity Index) dla obrazÃ³w
- **scikit-learn** - algorytmy klasteryzacji (KMeans)
- **UMAP** - redukcja wymiarowoÅ›ci
- **Comet ML** - trackowanie eksperymentÃ³w (opcjonalne)
- **python-dotenv** - zarzÄ…dzanie zmiennymi Å›rodowiskowymi
- **Jupyter** - Å›rodowisko notebookowe